# Libraries
library(caret)
library(skimr)
library(corrplot)
# Import and clean data
data <- read.csv("C:/Users/george/Documents/Digital Marketing Data/Triggers/spendingAndEnrollments.csv")
dataRGV <- data
dataRGV
# Split data
x <- subset(dataRGV, select = -Enrollments)
y <- subset(dataRGV, select = Enrollments)
# Data summary
skimX <- skim_to_wide(x)
skimY <- skim_to_wide(y)
skimX
skimY
# Data partition
seed <- 123
set.seed(seed)
dataPart <- createDataPartition(y$Enrollments,
p = .70,
list = FALSE)
xTrain <- x[dataPart,]
yTrain <- y[dataPart,]
xTest <- x[-dataPart,]
yTest <- y[-dataPart,]
# Create numeric set of x variables
xTrainNum <- as.data.frame(sapply(xTrain, as.numeric))
# Boxplot of predictors
boxplot(xTrainNum)
boxplot(yTrain)
# Histograms
hist(xTrainNum$Campaign)
hist(xTrainNum$Spending)
hist(as.numeric(yTrain))
# Correlation plots and correlation ceiling
correlations <- cor(xTrainNum)
corrplot(correlations, method = "number", order = "hclust")
# Model set up
dmy <- dummyVars(" ~ .", data = xTrain, fullRank = T)
xTrainDummy <- data.frame(predict(dmy, newdata = xTrain))
set.seed(seed)
ctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)
# Predictive modeling w/ built-in feature selection
gridBstLm <- expand.grid(mstop = seq(8, 12, by = 1), nu = 0.5)
set.seed(seed)
modelBstLm <- train(x = xTrainDummy, y = yTrain,
method = "BstLm",
preProc = c("center", "scale", "YeoJohnson", "spatialSign"),
tuneGrid = gridBstLm,
trControl = ctrl)
modelBstLm # RMSE = 5.36
gridEnet <- expand.grid(fraction = seq(0.6, 0.8, by = 0.1), lambda = 0)
set.seed(seed)
modelEnet <- train(x = xTrainDummy, y = yTrain,
method = "enet",
preProc = c("center", "scale", "YeoJohnson", "spatialSign"),
tuneGrid = gridEnet,
trControl = ctrl)
modelEnet # RMSE = 5.15
gridGlmNet <- expand.grid(alpha = c(0.9, 1, 1.1), lambda = c(0.6, 0.7, 0.8))
set.seed(seed)
modelGlmNet <- train(x = xTrainDummy, y = yTrain,
method = "glmnet",
preProc = c("center", "scale", "YeoJohnson", "spatialSign"),
tuneGrid = gridGlmNet,
trControl = ctrl)
modelGlmNet # RMSE = 5.17
gridLars <- expand.grid(fraction = c(0.65, 0.7, 0.75))
set.seed(seed)
modelLars <- train(x = xTrainDummy, y = yTrain,
method = "lars",
preProc = c("center", "scale", "YeoJohnson", "spatialSign"),
tuneGrid = gridLars,
trControl = ctrl)
modelLars # RMSE = 5.14
gridRF <- expand.grid(mtry = c(1.5, 2, 2.5))
set.seed(seed)
modelRF <- train(x = xTrainDummy, y = yTrain,
method = "rf",
preProc = c("center", "scale", "YeoJohnson", "spatialSign"),
tuneGrid = gridRF,
trControl = ctrl)
modelRF # RMSE = 4.99, R^2 = 0.74
# Compare model performances
modelResults <- resamples(list(BstLm = modelBstLm, Enet = modelEnet, GlmNet = modelGlmNet,
Lars = modelLars, RF = modelRF))
summary(modelResults)
dotplot(modelResults)
# Check differences
modelDiff <- diff(modelResults)
summary(modelDiff)
dotplot(modelDiff)
# Transform test data
dmyTest <- dummyVars(" ~ .", data = xTest, fullRank = T)
xTestDummy <- data.frame(predict(dmyTest, newdata = xTest))
# Evaluate on test data
predictRF <- predict(modelRF, newdata = xTestDummy)
RMSE(predictRF, yTest)
R2(predictRF, yTest)
# Finalize Model
library(randomForest)
set.seed(seed)
preProcParams <- preProcess(xTrainDummy, method = c("center", "scale", "YeoJohnson", "spatialSign"))
xTrainTrans <- predict(preProcParams, xTrainDummy)
finalModel <- randomForest(x = xTrainTrans, y = yTrain, mstop = 10)
finalModel
summary(finalModel)
# Evaluate on test data
xTestNum <- as.data.frame(sapply(xTest, as.numeric))
set.seed(seed)
xTestTrans <- predict(preProcParams, xTestDummy)
finalModelPredict <- predict(finalModel, newdata = xTestTrans, mstop = 10)
# Calculate performance
finalModelRMSE <- RMSE(finalModelPredict, yTest)
finalModelR2 <- R2(finalModelPredict, yTest)
finalModelRMSE
library(caretEnsemble)
# Train a list of models with caretList()
listOfModels <- c('rf', 'BstLm')
set.seed(seed)
modelList <- caretList(x = xTrainDummy, y = yTrain,
trControl = ctrl,
preProc = c("center", "scale", "YeoJohnson", "spatialSign"),
methodList = listOfModels)
# Model results and correlation
results <- resamples(modelList)
summary(results)
dotplot(results)
modelCor(results)
# Combine the models with caretEnsemble()
set.seed(seed)
modelEnsemble <- caretEnsemble(modelList, metric = "RMSE",
trControl = trainControl(number = 2))
summary(modelEnsemble) # RMSE = 5.0463
# Evaluate on test data
predictEnsemble <- predict(modelEnsemble, newdata = xTestDummy)
RMSE(predictEnsemble, yTest)
R2(predictEnsemble, yTest)
# Import and clean data
predData <- read.csv("C:/Users/george/Documents/Digital Marketing Data/Triggers/predictedSpendingAndEnrollments.csv")
# Transform forecast data
dmyPredData <- dummyVars(" ~ .", data = predData, fullRank = T)
predDummy <- data.frame(predict(dmyPredData, newdata = predData))
# Predict forecast data
predEnrollments <- data.frame(predict(modelEnsemble, newdata = predDummy))
predExport <- data.frame(c(predData,predEnrollments))
predExport
#write.csv(predExport, "C:/Users/george/Documents/Digital Marketing Data/Triggers/predictedExport.csv", row.names = FALSE)
